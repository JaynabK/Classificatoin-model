{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Enter any number : 6789876\nThe given number is PALINDROME\n"
                }
            ], 
            "source": "num = input('Enter any number : ')\ntry:\n    val = int(num)\n    if num == str(num)[::-1]:\n        print('The given number is PALINDROME')\n    else:\n        print('The given number is NOT a palindrome')\nexcept ValueError:\n    print(\"That's not a valid number, Try Again !\")"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "TypeError", 
                    "evalue": "'int' object is not iterable", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-10-7843584aea78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m            \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "N1=1\nN2=9\nresult=0\nfor i in range(N1, N2+1):\n        if(i%2!=0 and sum(map(int, i)/2==0)):\n           result=result+1\nprint(result)"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 11, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'0b101'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "bin(5)\n"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "str='10101'\n\n    "
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0\n"
                }
            ], 
            "source": "count=0\nfor i in range(len(str)-2):\n    sub = str[i:i+2]\n    if sub == '101':\n      count = count + 1\nprint (count)\n \n"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "101\n1\n010\n101\n2\n2\n"
                }
            ], 
            "source": "r=21\n\nb=bin(r)\nsub='101'\nc=0\ns = b.lstrip('-0b')\nfor i in range(0,len(s)-2):\n    print(s[i:i+3])\n    if(s[i:i+3]==sub):\n        c=c+1\n        print(c)\nprint(c)\n    \n\n\n"
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import re, string, unicodedata\nimport nltk\nimport parser\n\nfrom bs4 import BeautifulSoup\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/DSX-Python35\n\n  added / updated specs: \n    - spacy\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    preshed-1.0.1              |   py35hfc679d8_0         265 KB  conda-forge\n    certifi-2018.8.24          |        py35_1001         139 KB  conda-forge\n    ca-certificates-2019.6.16  |       hecc5488_0         145 KB  conda-forge\n    cymem-1.31.2               |           py35_0          67 KB  conda-forge\n    thinc-6.10.3               |   py35hf8a1672_2         3.4 MB  conda-forge\n    msgpack-python-0.5.6       |   py35h2d50403_3         300 KB  conda-forge\n    regex-2017.11.09           |           py35_0         1.1 MB  conda-forge\n    murmurhash-0.28.0          |py35hf484d3e_1000          16 KB  conda-forge\n    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n    ujson-1.35                 |py35h14c3975_1001          27 KB  conda-forge\n    openssl-1.0.2r             |       h14c3975_0         3.1 MB  conda-forge\n    plac-0.9.6                 |             py_1          18 KB  conda-forge\n    spacy-2.0.12               |   py35hf8a1672_0        82.2 MB  conda-forge\n    msgpack-numpy-0.4.4.3      |             py_0           8 KB  conda-forge\n    dill-0.2.8.2               |           py35_0         109 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        90.9 MB\n\nThe following NEW packages will be INSTALLED:\n\n    cymem:           1.31.2-py35_0            conda-forge\n    dill:            0.2.8.2-py35_0           conda-forge\n    msgpack-numpy:   0.4.4.3-py_0             conda-forge\n    murmurhash:      0.28.0-py35hf484d3e_1000 conda-forge\n    plac:            0.9.6-py_1               conda-forge\n    preshed:         1.0.1-py35hfc679d8_0     conda-forge\n    regex:           2017.11.09-py35_0        conda-forge\n    spacy:           2.0.12-py35hf8a1672_0    conda-forge\n    termcolor:       1.1.0-py_2               conda-forge\n    thinc:           6.10.3-py35hf8a1672_2    conda-forge\n    ujson:           1.35-py35h14c3975_1001   conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2019.1.23-0                          --> 2019.6.16-hecc5488_0 conda-forge\n    certifi:         2018.8.24-py35_1                     --> 2018.8.24-py35_1001  conda-forge\n    msgpack-python:  0.4.8-py35h783f4c8_0                 --> 0.5.6-py35h2d50403_3 conda-forge\n\nThe following packages will be DOWNGRADED:\n\n    openssl:         1.0.2s-h7b6447c_0                    --> 1.0.2r-h14c3975_0    conda-forge\n\n\nDownloading and Extracting Packages\npreshed-1.0.1        | 265 KB    | ##################################### | 100% \ncertifi-2018.8.24    | 139 KB    | ##################################### | 100% \nca-certificates-2019 | 145 KB    | ##################################### | 100% \ncymem-1.31.2         | 67 KB     | ##################################### | 100% \nthinc-6.10.3         | 3.4 MB    | ##################################### | 100% \nmsgpack-python-0.5.6 | 300 KB    | ##################################### | 100% \nregex-2017.11.09     | 1.1 MB    | ##################################### | 100% \nmurmurhash-0.28.0    | 16 KB     | ##################################### | 100% \ntermcolor-1.1.0      | 6 KB      | ##################################### | 100% \nujson-1.35           | 27 KB     | ##################################### | 100% \nopenssl-1.0.2r       | 3.1 MB    | ##################################### | 100% \nplac-0.9.6           | 18 KB     | ##################################### | 100% \nspacy-2.0.12         | 82.2 MB   | ##################################### | 100% \nmsgpack-numpy-0.4.4. | 8 KB      | ##################################### | 100% \ndill-0.2.8.2         | 109 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n"
                }
            ], 
            "source": "!conda install -c conda-forge spacy"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sample = \"\"\"<h1>Title Goes Here</h1>\n<b>Bolded Text</b>\n<i>Italicized Text</i>\n<img src=\"this should all be gone\"/>\n<a href=\"this will be gone, too\">But this will still be here!</a>\nI run. He ran. She is running. Will they stop running?\nI talked. She was talking. They talked to them about running. Who ran to the talking runner?\n[Some text we don't want to keep is in here]\n\u00a1Sebasti\u00e1n, Nicol\u00e1s, Alejandro and J\u00e9ronimo are going to the store tomorrow morning!\nsomething... is! wrong() with.,; this :: sentence.\nI can't do this anymore. I didn't know them. Why couldn't you have dinner at the restaurant?\nMy favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\nDon't do it.... Just don't. Billy! I know what you're doing. This is a great little house you've got here.\n[This is some other unwanted text]\nJohn: \"Well, well, well.\"\nJames: \"There, there. There, there.\"\n&nbsp;&nbsp;\nThere are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.\nI have to go get 2 tutus from 2 different stores, too.\n22    45   1067   445\n{{Here is some stuff inside of double curly braces.}}\n{Here is more stuff in single curly braces.}\n[DELETE]\n</body>\n</html>\"\"\""
        }, 
        {
            "source": "# Noise Removal", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Title Goes Here\nBolded Text\nItalicized Text\n\nBut this will still be here!\nI run. He ran. She is running. Will they stop running?\nI talked. She was talking. They talked to them about running. Who ran to the talking runner?\n\n\u00a1Sebasti\u00e1n, Nicol\u00e1s, Alejandro and J\u00e9ronimo are going to the store tomorrow morning!\nsomething... is! wrong() with.,; this :: sentence.\nI can't do this anymore. I didn't know them. Why couldn't you have dinner at the restaurant?\nMy favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\nDon't do it.... Just don't. Billy! I know what you're doing. This is a great little house you've got here.\n\nJohn: \"Well, well, well.\"\nJames: \"There, there. There, there.\"\n\u00a0\u00a0\nThere are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.\nI have to go get 2 tutus from 2 different stores, too.\n22    45   1067   445\n{{Here is some stuff inside of double curly braces.}}\n{Here is more stuff in single curly braces.}\n\n\n\n"
                }
            ], 
            "source": "def strip_html(text):\n    soup=BeautifulSoup(text,\"html.parser\")\n    return soup.get_text()\ndef remove_between_square_bracket(text):\n    return (re.sub('\\[[^]]*\\]',\"\",text))\ndef denoise_text(text):\n    text=strip_html(text)\n    text=remove_between_square_bracket(text)\n    return text\nprint(denoise_text(sample))"
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Title Goes Here\nBolded Text\nItalicized Text\n\nBut this will still be here!\nI run. He ran. She is running. Will they stop running?\nI talked. She was talking. They talked to them about running. Who ran to the talking runner?\n\n\u00a1Sebasti\u00e1n, Nicol\u00e1s, Alejandro and J\u00e9ronimo are going to the store tomorrow morning!\nsomething... is! wrong() with.,; this :: sentence.\nI cannot do this anymore. I did not know them. Why could not you have dinner at the restaurant?\nMy favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\ndo not do it.... Just do not. Billy! I know what you are doing. This is a great little house you have got here.\n\nJohn: \"Well, well, well.\"\nJames: \"There, there. There, there.\"\n\u00a0\u00a0\nThere are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.\nI have to go get 2 tutus from 2 different stores, too.\n22    45   1067   445\n{{Here is some stuff inside of double curly braces.}}\n{Here is more stuff in single curly braces.}\n\n\n\n"
                }
            ], 
            "source": "import contractions\ndef replace_contractions(text):\n    \"\"\"Replace contractions in string of text\"\"\"\n    return contractions.fix(text)\n\nsample = replace_contractions(sample)\nprint(sample)"
        }, 
        {
            "source": "# Tokenization", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "['Title', 'Goes', 'Here', 'Bolded', 'Text', 'Italicized', 'Text', 'But', 'this', 'will', 'still', 'be', 'here', '!', 'I', 'run', '.', 'He', 'ran', '.', 'She', 'is', 'running', '.', 'Will', 'they', 'stop', 'running', '?', 'I', 'talked', '.', 'She', 'was', 'talking', '.', 'They', 'talked', 'to', 'them', 'about', 'running', '.', 'Who', 'ran', 'to', 'the', 'talking', 'runner', '?', '\u00a1Sebasti\u00e1n', ',', 'Nicol\u00e1s', ',', 'Alejandro', 'and', 'J\u00e9ronimo', 'are', 'going', 'to', 'the', 'store', 'tomorrow', 'morning', '!', 'something', '...', 'is', '!', 'wrong', '(', ')', 'with.', ',', ';', 'this', ':', ':', 'sentence', '.', 'I', 'can', 'not', 'do', 'this', 'anymore', '.', 'I', 'did', 'not', 'know', 'them', '.', 'Why', 'could', 'not', 'you', 'have', 'dinner', 'at', 'the', 'restaurant', '?', 'My', 'favorite', 'movie', 'franchises', ',', 'in', 'order', ':', 'Indiana', 'Jones', ';', 'Marvel', 'Cinematic', 'Universe', ';', 'Star', 'Wars', ';', 'Back', 'to', 'the', 'Future', ';', 'Harry', 'Potter', '.', 'do', 'not', 'do', 'it', '...', '.', 'Just', 'do', 'not', '.', 'Billy', '!', 'I', 'know', 'what', 'you', 'are', 'doing', '.', 'This', 'is', 'a', 'great', 'little', 'house', 'you', 'have', 'got', 'here', '.', 'John', ':', '``', 'Well', ',', 'well', ',', 'well', '.', \"''\", 'James', ':', '``', 'There', ',', 'there', '.', 'There', ',', 'there', '.', \"''\", 'There', 'are', 'a', 'lot', 'of', 'reasons', 'not', 'to', 'do', 'this', '.', 'There', 'are', '101', 'reasons', 'not', 'to', 'do', 'it', '.', '1000000', 'reasons', ',', 'actually', '.', 'I', 'have', 'to', 'go', 'get', '2', 'tutus', 'from', '2', 'different', 'stores', ',', 'too', '.', '22', '45', '1067', '445', '{', '{', 'Here', 'is', 'some', 'stuff', 'inside', 'of', 'double', 'curly', 'braces', '.', '}', '}', '{', 'Here', 'is', 'more', 'stuff', 'in', 'single', 'curly', 'braces', '.', '}']\n"
                }
            ], 
            "source": "from nltk.tokenize import word_tokenize\n\nwords = word_tokenize(sample)\nprint(words)"
        }, 
        {
            "execution_count": 48, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "stopword = nltk.corpus.stopwords.words('english')# All English Stopwords"
        }, 
        {
            "source": "# Normalization\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 54, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "['titl', 'goe', 'bold', 'text', 'it', 'text', 'stil', 'run', 'ran', 'run', 'stop', 'run', 'talk', 'talk', 'talk', 'run', 'ran', 'talk', 'run', 'sebast', 'nicola', 'alejandro', 'jeronimo', 'going', 'stor', 'tomorrow', 'morn', 'someth', 'wrong', 'sent', 'anym', 'know', 'could', 'din', 'resta', 'favorit', 'movy', 'franch', 'ord', 'indian', 'jon', 'marvel', 'cinem', 'univers', 'star', 'war', 'back', 'fut', 'harry', 'pot', 'bil', 'know', 'gre', 'littl', 'hous', 'got', 'john', 'wel', 'wel', 'wel', 'jam', 'lot', 'reason', '101', 'reason', '1000000', 'reason', 'act', 'go', 'get', '2', 'tut', '2', 'diff', 'stor', '22', '45', '1067', '445', 'stuff', 'insid', 'doubl', 'cur', 'brac', 'stuff', 'singl', 'cur', 'brac']\n"
                }
            ], 
            "source": "def remove_non_ascii(words):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    new_words=[]\n    for word in words:\n        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        new_words.append(new_word)\n    return new_words\ndef to_lowercase(words):\n    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word=word.lower()\n        new_words.append(new_word)\n    return new_words\ndef remove_punctuation(words):\n    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word=re.sub(r'[^\\w\\s]','',word)\n        if new_word!='':\n            new_words.append(new_word)\n    return new_words\ndef remove_stopwords(words):\n    \"\"\"Remove stop words from list of tokenized words\"\"\"\n    new_words = [word for word in words if word not in stopword]\n    return new_words\ndef stem_words(words):\n    \"\"\"Stem words in list of tokenized words\"\"\"\n    stammer=LancasterStemmer()\n    new_words=[]\n    for word in words:\n        new_word=stammer.stem(word)\n        new_words.append(new_word)\n    return new_words\ndef lemmatize_verbs(words):\n    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n    lemmatizer=WordNetLemmatizer()\n    new_words=[]\n    for word in words:\n        new_word=lemmatizer.lemmatize(word)\n        new_words.append(new_word)\n    return new_words\ndef normalize(words):\n    words=remove_non_ascii(words)\n    words=to_lowercase(words)\n    words=remove_punctuation(words)\n    words=remove_stopwords(words)\n    words=stem_words(words)\n    words=lemmatize_verbs(words)\n    return(words)\nwords = normalize(words)\nprint(words)                    "
        }, 
        {
            "execution_count": 55, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(88, 68)\n['1000000', '101', '1067', '22', '445', '45', 'act', 'alejandro', 'anym', 'back', 'bil', 'bold', 'brac', 'cinem', 'could', 'cur', 'diff', 'din', 'doubl', 'favorit', 'franch', 'fut', 'get', 'go', 'goe', 'going', 'got', 'gre', 'harry', 'hous', 'indian', 'insid', 'it', 'jam', 'jeronimo', 'john', 'jon', 'know', 'littl', 'lot', 'marvel', 'morn', 'movy', 'nicola', 'ord', 'pot', 'ran', 'reason', 'resta', 'run', 'sebast', 'sent', 'singl', 'someth', 'star', 'stil', 'stop', 'stor', 'stuff', 'talk', 'text', 'titl', 'tomorrow', 'tut', 'univers', 'war', 'wel', 'wrong']\n"
                }
            ], 
            "source": "from sklearn.feature_extraction.text import CountVectorizer\n\ncount_vect = CountVectorizer()\nX_counts = count_vect.fit_transform(words)\nprint(X_counts.shape)\nprint(count_vect.get_feature_names())"
        }, 
        {
            "execution_count": 56, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 56, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<88x68 sparse matrix of type '<class 'numpy.int64'>'\n\twith 86 stored elements in Compressed Sparse Row format>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "X_counts"
        }, 
        {
            "execution_count": 58, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 58, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1000000</th>\n      <th>101</th>\n      <th>1067</th>\n      <th>22</th>\n      <th>445</th>\n      <th>45</th>\n      <th>act</th>\n      <th>alejandro</th>\n      <th>anym</th>\n      <th>back</th>\n      <th>...</th>\n      <th>stuff</th>\n      <th>talk</th>\n      <th>text</th>\n      <th>titl</th>\n      <th>tomorrow</th>\n      <th>tut</th>\n      <th>univers</th>\n      <th>war</th>\n      <th>wel</th>\n      <th>wrong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows \u00d7 68 columns</p>\n</div>", 
                        "text/plain": "   1000000  101  1067  22  445  45  act  alejandro  anym  back  ...    stuff  \\\n0        0    0     0   0    0   0    0          0     0     0  ...        0   \n1        0    0     0   0    0   0    0          0     0     0  ...        0   \n2        0    0     0   0    0   0    0          0     0     0  ...        0   \n3        0    0     0   0    0   0    0          0     0     0  ...        0   \n4        0    0     0   0    0   0    0          0     0     0  ...        0   \n5        0    0     0   0    0   0    0          0     0     0  ...        0   \n6        0    0     0   0    0   0    0          0     0     0  ...        0   \n7        0    0     0   0    0   0    0          0     0     0  ...        0   \n8        0    0     0   0    0   0    0          0     0     0  ...        0   \n9        0    0     0   0    0   0    0          0     0     0  ...        0   \n\n   talk  text  titl  tomorrow  tut  univers  war  wel  wrong  \n0     0     0     1         0    0        0    0    0      0  \n1     0     0     0         0    0        0    0    0      0  \n2     0     0     0         0    0        0    0    0      0  \n3     0     1     0         0    0        0    0    0      0  \n4     0     0     0         0    0        0    0    0      0  \n5     0     1     0         0    0        0    0    0      0  \n6     0     0     0         0    0        0    0    0      0  \n7     0     0     0         0    0        0    0    0      0  \n8     0     0     0         0    0        0    0    0      0  \n9     0     0     0         0    0        0    0    0      0  \n\n[10 rows x 68 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import pandas as pd\nX_counts_df = pd.DataFrame(X_counts.toarray(), columns=count_vect.get_feature_names())\nX_counts_df.head(10)"
        }, 
        {
            "execution_count": 62, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(88, 68)\n['1000000', '101', '1067', '22', '445', '45', 'act', 'alejandro', 'anym', 'back', 'bil', 'bold', 'brac', 'cinem', 'could', 'cur', 'diff', 'din', 'doubl', 'favorit', 'franch', 'fut', 'get', 'go', 'goe', 'going', 'got', 'gre', 'harry', 'hous', 'indian', 'insid', 'it', 'jam', 'jeronimo', 'john', 'jon', 'know', 'littl', 'lot', 'marvel', 'morn', 'movy', 'nicola', 'ord', 'pot', 'ran', 'reason', 'resta', 'run', 'sebast', 'sent', 'singl', 'someth', 'star', 'stil', 'stop', 'stor', 'stuff', 'talk', 'text', 'titl', 'tomorrow', 'tut', 'univers', 'war', 'wel', 'wrong']\n"
                }
            ], 
            "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vect = TfidfVectorizer()\nX_tfidf = tfidf_vect.fit_transform(words)\nprint(X_tfidf.shape)\nprint(tfidf_vect.get_feature_names())"
        }, 
        {
            "execution_count": 64, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "    1000000  101  1067   22  445   45  act  alejandro  anym  back  ...    \\\n0       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n1       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n2       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n3       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n4       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n5       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n6       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n7       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n8       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n9       0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n10      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n11      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n12      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n13      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n14      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n15      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n16      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n17      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n18      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n19      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n20      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n21      0.0  0.0   0.0  0.0  0.0  0.0  0.0        1.0   0.0   0.0  ...     \n22      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n23      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n24      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n25      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n26      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n27      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n28      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n29      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n..      ...  ...   ...  ...  ...  ...  ...        ...   ...   ...  ...     \n56      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n57      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n58      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n59      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n60      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n61      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n62      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n63      0.0  1.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n64      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n65      1.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n66      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n67      0.0  0.0   0.0  0.0  0.0  0.0  1.0        0.0   0.0   0.0  ...     \n68      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n69      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n71      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n73      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n74      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n75      0.0  0.0   0.0  1.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n76      0.0  0.0   0.0  0.0  0.0  1.0  0.0        0.0   0.0   0.0  ...     \n77      0.0  0.0   1.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n78      0.0  0.0   0.0  0.0  1.0  0.0  0.0        0.0   0.0   0.0  ...     \n79      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n80      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n81      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n82      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n83      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n84      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n85      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n86      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n87      0.0  0.0   0.0  0.0  0.0  0.0  0.0        0.0   0.0   0.0  ...     \n\n    stuff  talk  text  titl  tomorrow  tut  univers  war  wel  wrong  \n0     0.0   0.0   0.0   1.0       0.0  0.0      0.0  0.0  0.0    0.0  \n1     0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n2     0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n3     0.0   0.0   1.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n4     0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n5     0.0   0.0   1.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n6     0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n7     0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n8     0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n9     0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n10    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n11    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n12    0.0   1.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n13    0.0   1.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n14    0.0   1.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n15    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n16    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n17    0.0   1.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n18    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n19    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n20    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n21    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n22    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n23    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n24    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n25    0.0   0.0   0.0   0.0       1.0  0.0      0.0  0.0  0.0    0.0  \n26    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n27    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n28    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    1.0  \n29    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n..    ...   ...   ...   ...       ...  ...      ...  ...  ...    ...  \n56    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n57    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  1.0    0.0  \n58    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  1.0    0.0  \n59    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  1.0    0.0  \n60    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n61    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n62    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n63    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n64    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n65    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n66    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n67    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n68    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n69    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n71    0.0   0.0   0.0   0.0       0.0  1.0      0.0  0.0  0.0    0.0  \n73    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n74    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n75    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n76    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n77    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n78    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n79    1.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n80    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n81    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n82    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n83    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n84    1.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n85    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n86    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n87    0.0   0.0   0.0   0.0       0.0  0.0      0.0  0.0  0.0    0.0  \n\n[86 rows x 68 columns]\n"
                }
            ], 
            "source": "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vect.get_feature_names())\nX_tfidf_df.head(10)\nprint(X_tfidf_df.loc[(X_tfidf_df!=0).any(axis=1)])"
        }, 
        {
            "execution_count": 86, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 86, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Title Goes Here</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bolded Text</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Italicized Text</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>But this will still be here!</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I run. He ran. She is running. Will they stop ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I talked. She was talking. They talked to them...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\u00a1Sebasti\u00e1n, Nicol\u00e1s, Alejandro and J\u00e9ronimo ar...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>something... is! wrong() with.,; this :: sente...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>I cannot do this anymore. I did not know them....</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>My favorite movie franchises, in order: Indian...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>do not do it.... Just do not. Billy! I know wh...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>John: \"Well, well, well.\"</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>James: \"There, there. There, there.\"</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td></td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>There are a lot of reasons not to do this. The...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>I have to go get 2 tutus from 2 different stor...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>22    45   1067   445</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>{{Here is some stuff inside of double curly br...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>{Here is more stuff in single curly braces.}</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                                            body_text\n0                                     Title Goes Here\n1                                         Bolded Text\n2                                     Italicized Text\n4                        But this will still be here!\n5   I run. He ran. She is running. Will they stop ...\n6   I talked. She was talking. They talked to them...\n8   \u00a1Sebasti\u00e1n, Nicol\u00e1s, Alejandro and J\u00e9ronimo ar...\n9   something... is! wrong() with.,; this :: sente...\n10  I cannot do this anymore. I did not know them....\n11  My favorite movie franchises, in order: Indian...\n12  do not do it.... Just do not. Billy! I know wh...\n14                          John: \"Well, well, well.\"\n15               James: \"There, there. There, there.\"\n16                                                 \u00a0\u00a0\n17  There are a lot of reasons not to do this. The...\n18  I have to go get 2 tutus from 2 different stor...\n19                              22    45   1067   445\n20  {{Here is some stuff inside of double curly br...\n21       {Here is more stuff in single curly braces.}"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "data = sample\ndf = pd.DataFrame([x.split('\\n') for x in data.split('\\n')])\ndf.columns=['body_text']\nfilter = df[\"body_text\"] != \"\"\ndf = df[filter]\ndf"
        }, 
        {
            "execution_count": 91, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 91, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body_text</th>\n      <th>body_len</th>\n      <th>punct%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Title Goes Here</td>\n      <td>13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bolded Text</td>\n      <td>10</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Italicized Text</td>\n      <td>14</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>But this will still be here!</td>\n      <td>23</td>\n      <td>4.3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>I run. He ran. She is running. Will they stop ...</td>\n      <td>44</td>\n      <td>9.1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I talked. She was talking. They talked to them...</td>\n      <td>76</td>\n      <td>5.3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\u00a1Sebasti\u00e1n, Nicol\u00e1s, Alejandro and J\u00e9ronimo ar...</td>\n      <td>73</td>\n      <td>4.1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>something... is! wrong() with.,; this :: sente...</td>\n      <td>44</td>\n      <td>27.3</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>I cannot do this anymore. I did not know them....</td>\n      <td>77</td>\n      <td>3.9</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>My favorite movie franchises, in order: Indian...</td>\n      <td>108</td>\n      <td>6.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                                            body_text  body_len  punct%\n0                                     Title Goes Here        13     0.0\n1                                         Bolded Text        10     0.0\n2                                     Italicized Text        14     0.0\n4                        But this will still be here!        23     4.3\n5   I run. He ran. She is running. Will they stop ...        44     9.1\n6   I talked. She was talking. They talked to them...        76     5.3\n8   \u00a1Sebasti\u00e1n, Nicol\u00e1s, Alejandro and J\u00e9ronimo ar...        73     4.1\n9   something... is! wrong() with.,; this :: sente...        44    27.3\n10  I cannot do this anymore. I did not know them....        77     3.9\n11  My favorite movie franchises, in order: Indian...       108     6.5"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import string\n\n# Function to calculate length of message excluding space\ndf['body_len'] = df['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n\ndf.head()\n\ndef count_punct(text):\n    count = sum([1 for char in text if char in string.punctuation])\n    return round(count/(len(text) - text.count(\" \")), 3)*100\n\ndf['punct%'] = df['body_text'].apply(lambda x: count_punct(x))\n\ndf.head(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}